--- 7/9/23 ---

== sorting algs ==
selection sort - insertion sort
both O(n^2), lower constant factor (?) than bubble sort

sel sort:
partitioning: unsorted, sorted
iter: select smallest, move to start of sorted

note that in each iteration, only one item is resolved: therfore, total iterations is some approximation of (n^2)/2

ins sort:
similar partitioning
iter over each elem: loop through sorted and insert in appropriate pos
can binary search be used to achieve n log n? | this does not work because insertion necessarily require full swaps

item will take on average n/2 checks to find appropriate pos: therfore also (n^2)/2
(note that bubble sort can be similarly bound-checked to approximate (n^2)/2 operations)


remember that i,j = j,i exists

== big O notation ==
metric we use to describe approximately how #ops scales with n, the size of the input parameter

analogy: file on hard drive, need to send to friend a sufficiently large distance away
optimizing parameter is time of transfer
ftp vs. physical delivery - bandwidth problem

1 -> log n -> n -> n log n -> n^2 -> 2^n

--- continue 11/9/23 ---

big o, big theta, big omega

print all array vals: O(n)
formally, defined (in academia) as upper bound of time for an alg - alg is at least as fast as this

for all arr val: O(n) - takes <= ops O(n) to print n items

however we want O(n) to be asymptotically tight

big omega:
in academia: defined as lower bound to time for algorithm (cannot be significantly faster than this)
could instead be log n, or 1, but n is best approx

big theta:
in academia: both O() and big_omega() - in an alg, big_theta(n) if and only if O(n) and also big_omega(n)
tighter asymptotic bound

In industry this is diff: O(), big_theta() are equiv.
industry meaning of O() is similar to academically big_theta()

in this class, despite academically, we will use industry O(), optimize for tightest def. of runtime

best case, expected case, worst case = big_omega(), big_theta(), O()
X no particular relation

apply this on quicksort

== space complexity ==
sometimes memory is the limiting factor rather than time

arr of size n: O(n) space
2d arr: O(n^2) space

stack space in a recursive call:
sum: n-> if n<0 ret 0; ret n+sum(n-1);

stack space of O(n), time of O(n)

ex2 | pair_sum_seq: n-> sum=0; for i 0->n: sum+=pair_sum(i,i+1); ret sum;
	  pair_sum: a,b-> ret a+b;

time: O(n), stack: O(1)

dropping constants: O(n) code could run faster than O(1) for specific inputs: constant factor
O() only desc rate of increase, not the actual runtime

alg described as O(2n) is equiv to O(n)

dropping non-dominant terms: O(n^3 + n^2 + n) is equiv to O(n^3)

--- 13/9/23 ---

== merge sort ==

Subdivide the array into two sections, then recursively keep subdividing and merging these sections until sorted

merging: because both subarrays are sorted, create a sorted partition, and look at the leading members of each subarray
in turn until the whole array is finished

subrot: sort, merge

complexity: 3 visits per elem
if v(n) = time to sort array of len n, v(n) = v(n/2) + v(n/2) + 3n; or v(n)=2v(n/2)+3n
assume n=2^m: v(2^m)=2v(2^(m-1))+3n

Recursively we can derive that v(n) = 2^k v(n/(2^k)) + 3nk
therefore: defining a base case of v(1) = 1; v(n) = 2^(log n) + 3n(log n) -> n + 3n log n => O(n log n)
If v(1) = 0 (which is algorithmically possible) this will result in v(n) -> 3n log n

--- 27/9/23 ---

data types: a set of values and a set of operations that can be applied to said values

== abstraction ==

also encapsulation: construct that helps bundle data with methods (i.e. inline method instead of external func)

ADTs: data type whose representation gets hidden (?) from client - supports encapsulation in program design
	ex: do not need to know what bits do what / how datatype stores is implemented in order to use it - python dynamically allocated arrays

--- 29/9/23 ---

== hash tables ==

datastructure - maps keys to values for highly efficient lookup
number of ways to implement this | hash table / binary tree ?

simple implementation: array of linked lists
[
 & -> & -> ...
 & -> & -> ...
 ...
]
hashcode func: decompose any val into int/long rep

insertion: in -> key | hash_code(key) -> map hashcode to index in arr, and insert
however: collisions | because of this, allocate a new object and point to it w linked_list

retrieval: in -> key | hash(key)%len > map[index]; traverse ll until key; output value

prop of hash functions: take use of all info of key [ ex: do not use str[0] ]
hash values should be uniformly distributed
similar keys should output very different results
hash func must be fast

--- 17/10/23 ---

== images ==

processing stuff idk


--- 27/11/23 ---

== ADTs ==

abstract data types

== linked lists ==
	later: stacks, queues, trees, graphs

made up of nodes: node -> { value, next, [previous] }

singly-linked lists:
	*head -> first node -> second node -> etc. -> last node -> nil

iterating over ll:
	start at *head; call next() until next == nil

*cannot randomly access arbitrary element n at its direct memory location; must iterate
	additionally cannot traverse backwards

doubly-linked lists: each node stores *next, *previous
	*head -> first node <-> second <-> etc. <-> last -> nil
					 v
					nil
ops:
	build:
		node *current;
		void alloc(string value){
			current->next = new node();
			current = current->next;
			current->value = value;
			current->next = nil;
		}
		node first; first.value = "W"; first.next = nil;
		current = &first;
		alloc("T");
		alloc("Rocks!");

	insert @ begin:
		// pre: node *head, string val
		node new; new.value = val;
		new.next = head;
		next = &new;

	remove @ begin:
		// pre: node *head
		node *tmp = head->next;
		delete head->next;
		head = tmp;

	insert at end:
		// pre: node *head, string val
		node *tmp = head;
		while(tmp->next != nil) tmp = tmp->next;
		tmp->next = new node();
		(tmp->next)->value = val; (tmp->next)->next = nil;

	insert at n:
		// pre: node *head, int n, string val
		node *tmp = head;
		while(n-->0) tmp = tmp->next;
		node *ptr = tmp;
		tmp->next = new node();
		(tmp->next)->value = val; (tmp->next)->next = ptr;

--- 29/11/23 ---

== stacks ==

usually implemented with linked list ?

last in first out queue structure

push/pop ops

implementation:

ops:
	Stack(): creates new stack

	push(item): pushes item to stack

	pop(): returns topmost item in stack, and pops

	peek(): returns topmost item, does not modify

	isEmpty(): does what it looks like it does

	size(): read above

s = Stack()
op               stack              ret
s.isEmpty()     {}                  True
s.push(4)       {4}                 null
s.push("dog")   {4,"dog"}           null
s.peek()        {4,"dog"}           "dog"
s.push(True)    {4,"dog",True}      null
s.size()        {4,"dog",True}      3
s.isEmpty()     {4,"dog",True}      False
s.push(8.4)     {4,"dog",True,8.4}  null
s.pop()         {4,"dog",True}      8.4
s.pop()         {4,"dog"}           True
s.size()        {4,"dog"}           2

--- 7/12/23 ---

== queues ==

similar to stack: uses internal ll

ops:
	Queue(): ctor

	enqueue(item): insert into end

	dequeue(): return last item & pop

	size(): self explanatory
	isEmpty(): ^

op                   contents            ret
isEmpty           {}                     True
enqueue(4)        {4}
enqueue('dog')    {4,'dog'}
enqueue(True)     {4,'dog',True}
size              {4,'dog',True}         3
isEmpty           {4,'dog',True}         False
enqueue(8.4)      {4,'dog',True,8.4}
dequeue           {'dog',True,8.4}       4
dequeue           {True,8.4}             'dog'
size              {True,8.4}             2

--- 11/12/23 ---

== deque ==

double ll

ops:
	ctor()
	addFront(item)
	addRear(item)
	removeFront()
	removeRear()
	size()
	isEmpty()

--- 4/1/24 ---

== trees, graphs ==

def: list of nodes and edges btw them

+-------------+------+------------+
| application | item | connection |
+-------------+------+------------+
| map         | intr | roads      |
+-------------+------+------------+
| web content | page | hyperlink  |
+-------------+------+------------+
| circuit     | load | wire       |
+-------------+------+------------+
| schedule    | prsn | event      |
+-------------+------+------------+
| commerce    | prsn | trade      |
+-------------+------+------------+
| matching    | prsn | college    |
+-------------+------+------------+
| comp net    | comp | connection |
+-------------+------+------------+
| software    | intf | port       |
+-------------+------+------------+
| social net  | prsn | friendship |
+-------------+------+------------+

simple path:
0---1
	 \
	  2---3

non-simple path:
0---1   7----8
	 \ /
  5--2,6
   \   \
	4---3

--- 8/1/24 ---

cycles in graphs

a path that loops

simple cycle: no repeated v. except first,last

tree:
   4 5 6
	\|/
	 3    8
	 |   /
	 2--7--9
	/
0--1
	\      12
	 \     /
	 10--11--13
	  |
	 14
	 / \
	15 16

--- 10/1/24 ---

implementation of graphs in a standardized programming language (Python)

methods:
	ctor(int v): init graph datastructure with v vertices

	ctor(str i): create graph from input stream i

	v(), e(): counts of v,e

	add_edge(v,w): what it says it does

	adj(v): vertices adjacent to v; iterator

	dump(),print(): what it sounds like

implement with a form of adjacency matrix; links nodes to one another
theoretically implemented with a 2d bool arr

ex: graph
		  b
		 /
		a
	   /
	d-s
   /  |
  e---c
 /|   |
g |   |
 \|   |
  k---f
	   \
		j

  a b c d e f g j k s
a   1               1
b 1
c         1 1       1
d         1         1
e     1 1     1   1
f     1         1 1
g         1       1
j           1
k         1 1 1
s 1   1 1

--- 18/1/24 ---

== maze running ==

maze vs graph? functionally identical?

maze      |       graph
----------+------------
intersect |      vertex
----------+------------
path      |        edge

tremaux: originates from ball of yarn implementation

take any unmarked passage, unrolling a string behind you (save a stack of vertices previously traversed)
additionally, mark vertices as you pass them

retrace steps using string (stack) when approaching marked intersection

retrace steps when no unmarked options remaining at intersection

(essentially depth first search)

  b   d
 /   /
a   c---e
 \ / \  |
  s   f |
   \ /  |
	g---h

push items on stack and mark as visited
recursively either push next unvisited node onto stack or if impossible backtrack

dfs can find if 2 given vertices are connected or not

also, how many components does it have?

single source path problem:
	given graph, source vertex S, is there a path from S to given target vertex - if so find path

--- 9/2/24 ---

== dijkstra's algorithm ==

BFS for weighted graphs - requires priority queue (?) or other implementation of appendable sort

graph:

	b---3---e
   /|\     / \
  2 | 1   4   9
 /  |  \ /     \
a   6   d       g
 \  |          /
  5 |         7
   \|        /
	c---8---f

start from a, search for unexplored points, they become candidates for next move

a -> b,c candidates

set b,c to their current path cost if better than current

b,c -> 2,5

choose candidate with lowest cost

* -> b

add next candidates

b -> e,d candidates

set

e,d -> 5,3
b -\-> 8

choose

* -> d

d adds no candidates, c best

* -> c

add f

c -> f candidate

set

f -> 13

choose

e best

add g

e -> g candidate

g -> 14

practice:

	b--9->d
   >|     ^\
  7 |     | 1
 /  |     |  v
a   2     4   f
 \  |     |  ^
 12 |     | 5
   >v     |/
	c-10->e

x a 0
a b 7
b c 9
b d 16
c e 19
d f 17

* -> a
b,c -> 7,12 (a)
* -> b
c,d -> 9,16 (b)
* -> c
e -> 19 (c)
* -> d
f -> 17 (d)
* -> f
* -> e

finished:

  b--d
 /|   \
a |    f
  |
  c--e

practice:

a | b20 f10 g25
b | c15 g3
c | d3
d | e4 g10
e |
f | c20 e30
g | c2 f3

x a 0
a b 20
g c 25
c d 28
d e 32
a f 10
b g 23

*a a>bfg *f f>ce *b b>g *g g>c *c c>d *d d>e

  a
 / \
f   b
   /
  g
   \
e   c
 \ /
  d

== types of search algorithms ==

1. uninformed search
	* linear search
	* binary search
	* DFS, BFS

	algorithms don't know anything about what they are searching for &
	where to search for it; they don't know where to head to optimally
	find the target, or the best chances

2. informed search
	algorithm is aware of where the best chances are of finding the target
	and the algorithm moves in this direction

	heuristic search is informed search technique that does not necessarily
	find the optimal path, but finds a reasonably good path - finds earliest
	path rather than fastest

--- 13/2/24 ---

another type of uninformed search: uniform cost search

== a* ==

heuristic approach to best path problem
	finds estimate to cost of taking a given path

for this algorithm to work, the heuristic needs to be less than or equal to
the actual cost

algorithm computes an "a* score", representing the cost of current path +
heuristic of ending node

essentially, traversal is similar to uniform cost, however, prioritize on a* score
rather than total path score

--- 1/4/24 ---

== priority queues ==

many applications require the use of a pq - a way to process items with keys in order
	not necessarily in full sorted order (?)
	not necessarily all at once

brief:
	push(item) -> [nil]
		add item to queue

	pop() -> [nil]
		remove highest item from queue
	
	top() -> [item]
		return item with highest key

ex. a cellphone running multiple tasks will prioritize a phone call over the news app

java-style pseudo-impl: (haskell type sig)

MaxPQ()           -> empty priority queue
MaxPQ(int max)    -> create pq with capacity `max`
MaxPQ(Key[] a)    -> pq from keys in a :: [Key]
insert(Key v)     -> insert a key
max() :: Key      -> return maximum
delMax()          -> pop maximum out of queue
isEMpty() :: Bool -> check if empty
size() :: Int     -> return size of queue

organization : insert   : remove
ordered      : O(n)     : O(1)
unordered    : O(1)     : O(n)
heap         : O(log n) : O(log n)

== heaps ==

binary tree-like structure that encapsulates a "pile of items"

stored in an array such that each key is guaranteed to be larger than or equal to the ones
at two other specific positions, recursively

a binary tree is heap-ordered if satisfies such heap condition

so like a segtree!
